{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorboard\n",
    "# !pip install ipywidgets widgetsnbextension pandas-profiling\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, fbeta_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup\n",
    "import copy\n",
    "import re\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Sep 30 23:47:23 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 108...  On   | 00000000:04:00.0 Off |                  N/A |\n",
      "| 41%   70C    P2    88W / 250W |   6399MiB / 11178MiB |     88%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce GTX 108...  On   | 00000000:06:00.0 Off |                  N/A |\n",
      "| 43%   73C    P2    92W / 250W |   4591MiB / 11178MiB |     48%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce GTX 108...  On   | 00000000:07:00.0 Off |                  N/A |\n",
      "| 48%   79C    P2    94W / 250W |   4591MiB / 11178MiB |     48%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce GTX 108...  On   | 00000000:08:00.0 Off |                  N/A |\n",
      "| 42%   74C    P2   150W / 250W |   4543MiB / 11178MiB |     49%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  GeForce GTX 108...  On   | 00000000:0C:00.0 Off |                  N/A |\n",
      "| 46%   78C    P2   207W / 250W |   4543MiB / 11178MiB |     50%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  GeForce GTX 108...  On   | 00000000:0D:00.0 Off |                  N/A |\n",
      "| 38%   70C    P2   213W / 250W |   4591MiB / 11178MiB |     45%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  GeForce GTX 108...  On   | 00000000:0E:00.0 Off |                  N/A |\n",
      "| 51%   82C    P2   213W / 250W |   4591MiB / 11178MiB |     60%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  GeForce GTX 108...  On   | 00000000:0F:00.0 Off |                  N/A |\n",
      "| 46%   78C    P2   217W / 250W |   4519MiB / 11178MiB |     67%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0    719561      C   ...ignateGithub/signate_471/abc/bin/python  6387MiB |\n",
      "|    1    719561      C   ...ignateGithub/signate_471/abc/bin/python  4579MiB |\n",
      "|    2    719561      C   ...ignateGithub/signate_471/abc/bin/python  4579MiB |\n",
      "|    3    719561      C   ...ignateGithub/signate_471/abc/bin/python  4531MiB |\n",
      "|    4    719561      C   ...ignateGithub/signate_471/abc/bin/python  4531MiB |\n",
      "|    5    719561      C   ...ignateGithub/signate_471/abc/bin/python  4579MiB |\n",
      "|    6    719561      C   ...ignateGithub/signate_471/abc/bin/python  4579MiB |\n",
      "|    7    719561      C   ...ignateGithub/signate_471/abc/bin/python  4507MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>judgement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>One-year age changes in MRI brain volumes in o...</td>\n",
       "      <td>Longitudinal studies indicate that declines in...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Supportive CSF biomarker evidence to enhance t...</td>\n",
       "      <td>The present study was undertaken to validate t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Occurrence of basal ganglia germ cell tumors w...</td>\n",
       "      <td>Objective: To report a case series in which ba...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>New developments in diagnosis and therapy of C...</td>\n",
       "      <td>The etiology and pathogenesis of idiopathic ch...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Prolonged shedding of SARS-CoV-2 in an elderly...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title  \\\n",
       "0   0  One-year age changes in MRI brain volumes in o...   \n",
       "1   1  Supportive CSF biomarker evidence to enhance t...   \n",
       "2   2  Occurrence of basal ganglia germ cell tumors w...   \n",
       "3   3  New developments in diagnosis and therapy of C...   \n",
       "4   4  Prolonged shedding of SARS-CoV-2 in an elderly...   \n",
       "\n",
       "                                            abstract  judgement  \n",
       "0  Longitudinal studies indicate that declines in...          0  \n",
       "1  The present study was undertaken to validate t...          0  \n",
       "2  Objective: To report a case series in which ba...          0  \n",
       "3  The etiology and pathogenesis of idiopathic ch...          0  \n",
       "4                                                NaN          0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n"
     ]
    }
   ],
   "source": [
    "#border = len(train_df[train_df[\"judgement\"] == 1]) / len(train_df[\"judgement\"])\n",
    "border = 0.01\n",
    "print(border)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27145"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              0\n",
       "title           0\n",
       "abstract     4390\n",
       "judgement       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>judgement</th>\n",
       "      <th>title_and_abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>One-year age changes in MRI brain volumes in o...</td>\n",
       "      <td>Longitudinal studies indicate that declines in...</td>\n",
       "      <td>0</td>\n",
       "      <td>One-year age changes in MRI brain volumes in o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Supportive CSF biomarker evidence to enhance t...</td>\n",
       "      <td>The present study was undertaken to validate t...</td>\n",
       "      <td>0</td>\n",
       "      <td>Supportive CSF biomarker evidence to enhance t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Occurrence of basal ganglia germ cell tumors w...</td>\n",
       "      <td>Objective: To report a case series in which ba...</td>\n",
       "      <td>0</td>\n",
       "      <td>Occurrence of basal ganglia germ cell tumors w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>New developments in diagnosis and therapy of C...</td>\n",
       "      <td>The etiology and pathogenesis of idiopathic ch...</td>\n",
       "      <td>0</td>\n",
       "      <td>New developments in diagnosis and therapy of C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Prolonged shedding of SARS-CoV-2 in an elderly...</td>\n",
       "      <td>Prolonged shedding of SARS-CoV-2 in an elderly...</td>\n",
       "      <td>0</td>\n",
       "      <td>Prolonged shedding of SARS-CoV-2 in an elderly...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title  \\\n",
       "0   0  One-year age changes in MRI brain volumes in o...   \n",
       "1   1  Supportive CSF biomarker evidence to enhance t...   \n",
       "2   2  Occurrence of basal ganglia germ cell tumors w...   \n",
       "3   3  New developments in diagnosis and therapy of C...   \n",
       "4   4  Prolonged shedding of SARS-CoV-2 in an elderly...   \n",
       "\n",
       "                                            abstract  judgement  \\\n",
       "0  Longitudinal studies indicate that declines in...          0   \n",
       "1  The present study was undertaken to validate t...          0   \n",
       "2  Objective: To report a case series in which ba...          0   \n",
       "3  The etiology and pathogenesis of idiopathic ch...          0   \n",
       "4  Prolonged shedding of SARS-CoV-2 in an elderly...          0   \n",
       "\n",
       "                                  title_and_abstract  \n",
       "0  One-year age changes in MRI brain volumes in o...  \n",
       "1  Supportive CSF biomarker evidence to enhance t...  \n",
       "2  Occurrence of basal ganglia germ cell tumors w...  \n",
       "3  New developments in diagnosis and therapy of C...  \n",
       "4  Prolonged shedding of SARS-CoV-2 in an elderly...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_texts(df):\n",
    "    titles_and_abstracts = df['title_and_abstract'].values.tolist()\n",
    "    return titles_and_abstracts\n",
    "\n",
    "def get_labels(df):\n",
    "    labels = df.iloc[:, 3].values\n",
    "    return labels\n",
    "\n",
    "def clean_text(text):\n",
    "\n",
    "    if type(text) == float:\n",
    "        text = ''\n",
    "    #print(text)\n",
    "    \n",
    "    #text = text.lower()\n",
    "    \n",
    "    text = text.split()\n",
    "    text = [x.strip() for x in text]\n",
    "    text = [x.replace('\\n', ' ').replace('\\t', ' ') for x in text]\n",
    "    text = ' '.join(text)\n",
    "    text = re.sub('([.,!?()])', r' \\1 ', text)\n",
    "    #text = re.sub(r\"(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", text)\n",
    "    \n",
    "    \n",
    "    text = preprocess(text)\n",
    "    \n",
    "    #remove stopwords\n",
    "    #stop = stopwords.words('english')\n",
    "    #text = \" \".join([word for word in text.split() if word not in (stop)])\n",
    "    \n",
    "    return text\n",
    "\n",
    "def preprocess(sentence):\n",
    "    sentence = replace_double_quotation(sentence)\n",
    "    sentence = replace_garbled_text(sentence)\n",
    "    return sentence\n",
    "\n",
    "def replace_garbled_text(sentence):\n",
    "    garbled_char_table = {\n",
    "        'Â©': '©', '–': '-', '‐': '-',\n",
    "        'ﾂ｣': '£', 'ﾂｩ': '©', 'ﾂｫ': '«', 'ﾂｮ': '®', 'ﾂｰ': '°', 'ﾂｱ': '±', 'ﾂｲ': '²', 'ﾂｳ': '³', 'ﾂｴ': '´', 'ﾂｵ': 'µ', 'ﾂｷ': '·', 'ﾂｸ': '¸', 'ﾂｹ': '¹', 'ﾂｼ': '¼', 'ﾂｽ': '½', 'ﾂｾ': '¾', 'ﾂｿ': '¿', 'ﾂ': '',\n",
    "        'ﾃｷ': '÷', 'ﾃｸ': 'ø', 'ﾃ': 'a', 'ﾃ｡': 'a', 'ﾃ｢': 'a', 'ﾃ｣': 'a', 'ﾃ､': 'a', 'ﾃ･': 'a', 'ﾃｦ': 'ae', 'ﾃｧ': 'c', 'ﾃｨ': 'e', 'ﾃｩ': 'e', 'ﾃｪ': 'e', 'ﾃｫ': 'e',\n",
    "        'ﾃｬ': 'i', 'ﾃｭ': 'i', 'ﾃｮ': 'i', 'ﾃｯ': 'i', 'ﾃｱ': 'n', 'ﾃｲ': 'o', 'ﾃｳ': 'o', 'ﾃｴ': 'o', 'ﾃｵ': 'o', 'ﾃｶ': 'o', 'ﾃｹ': 'u', 'ﾃｺ': 'u', 'ﾃｻ': 'u', 'ﾃｼ': 'u', 'ﾃｽ': 'y', 'ﾃｿ': 'y', 'ﾃ': '×', \n",
    "        'ﾎｱ': 'α', 'ﾎｲ': 'β', 'ﾎｳ': 'γ', 'ﾎｴ': 'δ', 'ﾎｵ': 'ε', 'ﾎｶ': 'ζ', 'ﾎｷ': 'η', 'ﾎｸ': 'θ', 'ﾎｹ': 'ι', 'ﾎｺ': 'κ', 'ﾎｻ': 'λ', 'ﾎｼ': 'μ', 'ﾎｽ': 'ν', 'ﾎｾ': 'ξ', 'ﾎｿ': 'ο', 'ﾎ': '',\n",
    "        'ﾏ': ' ',\n",
    "        '竕､': '≤', '竕･': '≥', '竕ｦ': '≦', '竕ｧ': '≧',\n",
    "        '窶｢': '•', '窶ｦ': '…', '窶ｲ': '′', '窶ｳ': '″', '窶ｴ': '‴', '窶': ' ',\n",
    "        '竅ｰ': '⁰', '竅ｴ': '⁴', '竅ｵ': '⁵', '竅ｶ': '⁶', '竅ｷ': '⁷', '竅ｸ': '⁸', '竅ｹ': '⁹', '竅ｺ': '⁺', '竅ｻ': '⁻', '竅ｼ': '⁼', \n",
    "        '竏･': '∥', '竏ｪ': '∪', '竏ｫ': '∫', '竏ｶ': '∶', '竏ｼ': '∼', '竏': '', \n",
    "        'ﾂ\\uf8f0': ' '\n",
    "    }\n",
    "    for garbled_char, valid_char in garbled_char_table.items():\n",
    "        sentence = sentence.replace(garbled_char, valid_char)\n",
    "    sentence = re.sub('[ぁ-んァ-ンｦ-ﾟ一-龥]', '', sentence)\n",
    "    return sentence.translate(garbled_char_table)\n",
    "\n",
    "def replace_double_quotation(sentence):\n",
    "    return sentence.replace('\"', \"'\")  \n",
    "\n",
    "def clean_data(train_df):\n",
    "    train_df.loc[train_df['abstract'].isnull(), 'abstract'] = train_df['title']\n",
    "    train_df['abstract'] = train_df['abstract'].apply(clean_text)\n",
    "    train_df['title'] = train_df['title'].apply(clean_text)\n",
    "    return train_df\n",
    "\n",
    "def concat(train_df):\n",
    "    train_df['title_and_abstract'] = train_df['title'] + train_df['abstract']\n",
    "    return train_df\n",
    "\n",
    "train_df.loc[[2488,7708],['judgement']] = 0\n",
    "train_df = clean_data(train_df)\n",
    "test_df= clean_data(test_df)\n",
    "train_df = concat(train_df)\n",
    "test_df = concat(test_df)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-year age changes in MRI brain volumes in older adults . Longitudinal studies indicate that declines in cognition and memory accelerate after age 70 years .  The neuroanatomic and neurophysiologic underpinnings of cognitive change are unclear as there is little information on longitudinal brain changes .  We are conducting a longitudinal neuroimaging study of nondemented older participants in the Baltimore Longitudinal Study of Aging .  This report focuses on age and sex differences in brain structure measured by magnetic resonance imaging during the first two annual evaluations .  Cross-sectional results from 116 participants aged 59-85 years reveal significantly larger ventricular volumes and smaller gray and white matter volumes in older compared with younger participants and in men compared with women .  Regional brain volumes show that the effects of age and sex are not uniform across brain regions .  Age differences are greatest for the parietal region .  Sex differences tend to be larger for frontal and temporal than parietal and occipital regions .  Longitudinal analysis demonstrates an increase of 1526 mm ( 3 )  in ventricular volume over 1 year but no detectable change in total or regional brain volumes .  Definition of the pattern and rate of longitudinal brain changes will facilitate the detection of pathological brain changes which may be predictors of dementia . \n"
     ]
    }
   ],
   "source": [
    "print(train_df.loc[0,'title_and_abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                    0\n",
       "title                 0\n",
       "abstract              0\n",
       "title_and_abstract    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().sum()\n",
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax = sns.countplot(x='judgement', data=train_df)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = train_df['title'].tolist()\n",
    "# y = [len(t.split()) for t in title]\n",
    "# x = range(0, len(y))\n",
    "# plt.bar(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract = train_df['abstract'].tolist()\n",
    "# y = [len(a.split()) for a in abstract]\n",
    "# x = range(0, len(y))\n",
    "# plt.bar(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self):\n",
    "        super(Config, self).__init__()\n",
    "        \n",
    "        self.SEED = 42\n",
    "        self.MODEL_PATH = 'microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract'\n",
    "        self.NUM_LABELS = 1\n",
    "        \n",
    "        self.TOKENIZER = AutoTokenizer.from_pretrained(self.MODEL_PATH)\n",
    "        self.MAX_LENGTH = 512\n",
    "        self.BATCH_SIZE = 32\n",
    "        self.N_SPLIT = 5\n",
    "        \n",
    "        self.DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.FULL_FINETUNING = True\n",
    "        self.LR = 2e-5\n",
    "        self.OPTIMIZER = 'AdamW'\n",
    "        self.CRITERION = 'BCEWithLogitsLoss'\n",
    "        self.SAVE_BEST_ONLY = True\n",
    "        self.N_VALIDATE_DUR_TRAIN = 1\n",
    "        self.EPOCHS = 2 \n",
    "        \n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_init(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed = config.SEED\n",
    "seed_init(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDataset(Dataset):\n",
    "    def __init__(self, df, indices, set_type=None):\n",
    "        super(TransformerDataset, self).__init__()\n",
    "\n",
    "        df = df.iloc[indices]\n",
    "        self.titles_and_abstracts = get_texts(df)\n",
    "        self.set_type = set_type\n",
    "        if self.set_type != 'test':\n",
    "            self.labels = get_labels(df)\n",
    "\n",
    "        self.max_length = config.MAX_LENGTH\n",
    "        self.tokenizer = config.TOKENIZER\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.titles_and_abstracts)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        tokenized_titles_and_abstracts = self.tokenizer.encode_plus(\n",
    "            self.titles_and_abstracts[index], \n",
    "            max_length=self.max_length,\n",
    "            pad_to_max_length=True,\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_token_type_ids=False,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        input_ids_titles_and_abstracts = tokenized_titles_and_abstracts['input_ids'].squeeze()\n",
    "        attention_mask_titles_and_abstracts = tokenized_titles_and_abstracts['attention_mask'].squeeze()\n",
    "        \n",
    "\n",
    "        if self.set_type != 'test':\n",
    "            return {\n",
    "                'titles_and_abstracts': {\n",
    "                    'input_ids': input_ids_titles_and_abstracts.long(),\n",
    "                    'attention_mask': attention_mask_titles_and_abstracts.long(),\n",
    "                },\n",
    "                'labels': torch.Tensor([self.labels[index]]).float(),\n",
    "            }\n",
    "\n",
    "        return {\n",
    "            'titles_and_abstracts': {\n",
    "                'input_ids': input_ids_titles_and_abstracts.long(),\n",
    "                'attention_mask': attention_mask_titles_and_abstracts.long(),\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PubMedBert(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PubMedBert, self).__init__()\n",
    "        self.model = AutoModel.from_pretrained(config.MODEL_PATH)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        self.avgpool = nn.AvgPool1d(2, 2)\n",
    "        self.linear = nn.Linear(768, config.NUM_LABELS)\n",
    "    \n",
    "    def forward(self, input_ids_titles_and_abstracts, attention_mask_titles_and_abstracts=None):\n",
    "        output = self.model(input_ids=input_ids_titles_and_abstracts, attention_mask=attention_mask_titles_and_abstracts)\n",
    "        features = output.pooler_output\n",
    "        features = features.unsqueeze(1)\n",
    "        features_pooled = self.avgpool(features)\n",
    "        features_pooled = features_pooled.squeeze(1)\n",
    "\n",
    "        x = self.dropout(features)\n",
    "        x = self.linear(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(model, val_dataloader, criterion, epoch):\n",
    "    val_loss = 0\n",
    "    true, pred, output = [], [], []\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    for step, batch in tqdm(enumerate(val_dataloader), total=len(val_dataloader)):\n",
    "        b_input_ids = batch['titles_and_abstracts']['input_ids'].to(device)\n",
    "        b_attention_mask = batch['titles_and_abstracts']['attention_mask'].to(device)\n",
    "        b_labels = batch['labels'].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model(b_input_ids, b_attention_mask)\n",
    "            logits = logits.view(-1, 1)\n",
    "            loss = criterion(logits, b_labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            logits = torch.sigmoid(logits)\n",
    "            logits = logits.to('cpu').detach().numpy().copy()\n",
    "            output.extend(logits.tolist())\n",
    "            logits = np.where(logits < border, 0, 1)\n",
    "            labels = b_labels.to('cpu').detach().numpy().copy()\n",
    "            \n",
    "            pred.extend(logits)\n",
    "            true.extend(labels)\n",
    "            \n",
    "    output0, output1 = [], []\n",
    "    for p, o in zip(true, output):\n",
    "        if p == 0:\n",
    "            output0.append(o[0])\n",
    "        else:\n",
    "            output1.append(o[0])\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(1,2,1)\n",
    "    ax1.hist(output0, bins=100, color='red', alpha=0.5)\n",
    "    ax1.set_xlabel('output')\n",
    "    ax1.set_ylabel('sum')\n",
    "    ax1.set_title('val_0')\n",
    "    \n",
    "    ax2 = fig.add_subplot(1,2,2)\n",
    "    ax2.hist(output1, bins=100, color='blue', alpha=0.5)\n",
    "    ax2.set_xlabel('output')\n",
    "    ax2.set_ylabel('sum')\n",
    "    ax2.set_title('val_1')\n",
    "    \n",
    "    fig.savefig('graph/val_scibert'+str(epoch)+'.png')\n",
    "        \n",
    "    avg_val_loss = val_loss / len(val_dataloader)\n",
    "    print('Val loss:', avg_val_loss)\n",
    "    print('Val accuracy:', accuracy_score(true, pred))\n",
    "    \n",
    "    val_fbeta_score = fbeta_score(true, pred, beta=7.0)\n",
    "    print('Val fbeta score:', val_fbeta_score)\n",
    "    return val_fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataloader, val_dataloader, criterion, optimizer, scheduler, epoch):\n",
    "    nv = config.N_VALIDATE_DUR_TRAIN\n",
    "    temp = len(train_dataloader) // nv\n",
    "    temp = temp - (temp%100)\n",
    "    validate_at_steps = [temp * x for x in range(1, nv+1)]\n",
    "    \n",
    "    train_loss = 0\n",
    "    true, pred, output = [], [], []\n",
    "    for step, batch in tqdm(enumerate(train_dataloader), desc='Epoch ' + str(epoch), total=len(train_dataloader)):\n",
    "        \n",
    "        model.train()\n",
    "        b_input_ids = batch['titles_and_abstracts']['input_ids'].to(device)\n",
    "        b_attention_mask = batch['titles_and_abstracts']['attention_mask'].to(device)\n",
    "        b_labels = batch['labels'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        logits = model(b_input_ids, b_attention_mask)\n",
    "        logits = logits.view(-1, 1)\n",
    "#         print(\"logits=\",logits)\n",
    "        loss = criterion(logits, b_labels)\n",
    "        train_loss += loss.item()\n",
    "#         print(train_loss)\n",
    "        \n",
    "        logits = torch.sigmoid(logits)\n",
    "        logits = logits.to('cpu').detach().numpy().copy()\n",
    "        output.extend(logits.tolist())\n",
    "        logits = np.where(logits < border, 0, 1)\n",
    "        labels = b_labels.to('cpu').detach().numpy().copy()\n",
    "            \n",
    "        pred.extend(logits)\n",
    "        true.extend(labels)\n",
    "            \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        \n",
    "        #if step in validate_at_steps:\n",
    "        #    print(f'-- Step: {step}')\n",
    "        #    _ = val(model, val_dataloader, criterion)\n",
    "        \n",
    "    output0, output1 = [], []\n",
    "    for p, o in zip(true, output):\n",
    "        if p == 0:\n",
    "            output0.append(o[0])\n",
    "        else:\n",
    "            output1.append(o[0])\n",
    "            \n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(1,2,1)\n",
    "    ax1.hist(output0, bins=100, color='red', alpha=0.5)\n",
    "    ax1.set_xlabel('output')\n",
    "    ax1.set_ylabel('sum')\n",
    "    ax1.set_title('train_0')\n",
    "\n",
    "    ax2 = fig.add_subplot(1,2,2)\n",
    "    ax2.hist(output1, bins=100, color='blue', alpha=0.5)\n",
    "    ax2.set_xlabel('output')\n",
    "    ax2.set_ylabel('sum')\n",
    "    ax2.set_title('train_1')\n",
    "    \n",
    "    fig.savefig('graph/train_scibert'+str(epoch)+'.png')\n",
    "    \n",
    "    avg_train_loss = train_loss / len(train_dataloader)\n",
    "    accuracy = accuracy_score(true, pred)\n",
    "    train_fbeta_score = fbeta_score(true, pred, beta=7.0)\n",
    "    print('Training loss:', avg_train_loss)\n",
    "    print('Training accuracy:', accuracy_score)\n",
    "    print('Train fbeta score:', train_fbeta_score)\n",
    "    return avg_train_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(train_dataloader, val_dataloader, writer):\n",
    "    \n",
    "    !jupyter nbextension enable --py --sys-prefix widgetsnbextension\n",
    "    torch.cuda.empty_cache()\n",
    "    model = PubMedBert()\n",
    "    model=nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "    \n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    if config.FULL_FINETUNING:\n",
    "        param_optimizer = list(model.named_parameters())\n",
    "        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "        optimizer_parameters = [\n",
    "            {\n",
    "                \"params\": [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": 0.001,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": 0.0,\n",
    "            },\n",
    "        ]\n",
    "        optimizer = optim.AdamW(optimizer_parameters, lr=config.LR)\n",
    "    \n",
    "    num_training_steps = len(train_dataloader) * config.EPOCHS\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n",
    "    \n",
    "    max_val_fbeta_score = float('-inf')\n",
    "    for epoch in range(config.EPOCHS):\n",
    "        avg_train_loss, accuracy = train(model, train_dataloader, val_dataloader, criterion, optimizer, scheduler, epoch)\n",
    "        val_fbeta_score = val(model, val_dataloader, criterion, epoch)\n",
    "        \n",
    "        writer.add_scalar('train_loss', avg_train_loss, epoch+1)\n",
    "        writer.add_scalar('accuracy', accuracy, epoch+1)\n",
    "        writer.add_scalar('val_fbeta_score', val_fbeta_score, epoch+1)\n",
    "        \n",
    "        if config.SAVE_BEST_ONLY:\n",
    "            if val_fbeta_score > max_val_fbeta_score:\n",
    "                max_val_fbeta_score = val_fbeta_score\n",
    "                best_model = copy.deepcopy(model)\n",
    "                \n",
    "    return best_model, max_val_fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val():\n",
    "    Fold = StratifiedKFold(n_splits=config.N_SPLIT, shuffle=True, random_state=seed)\n",
    "    max_val_fbeta_score = float('-inf')\n",
    "    \n",
    "    for n, (train_indices, val_indices) in enumerate(Fold.split(train_df, train_df['judgement'])):\n",
    "        print(f'========= fold: {n} training =========')\n",
    "        \n",
    "        log_dir = 'logs/fold_scibert'+str(n)\n",
    "        if not os.path.exists(log_dir):\n",
    "            os.makedirs(log_dir)\n",
    "        \n",
    "        writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "        train_data = TransformerDataset(train_df, train_indices)\n",
    "        val_data = TransformerDataset(train_df, val_indices)\n",
    "        \n",
    "        train_dataloader = DataLoader(train_data, batch_size=config.BATCH_SIZE)\n",
    "        val_dataloader = DataLoader(val_data, batch_size=config.BATCH_SIZE)\n",
    "                \n",
    "        fold_best_model, fold_best_val_fbeta_score = run(train_dataloader, val_dataloader, writer)\n",
    "        \n",
    "        if config.SAVE_BEST_ONLY:\n",
    "            if fold_best_val_fbeta_score > max_val_fbeta_score:\n",
    "                best_model = fold_best_model\n",
    "                max_val_fbeta_score = fold_best_val_fbeta_score\n",
    "                \n",
    "                model_name = 'pubmed_model'\n",
    "                torch.save(best_model.module.state_dict(), model_name+'.pt')\n",
    "        \n",
    "        writer.close()\n",
    "                \n",
    "    return best_model, max_val_fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = config.DEVICE\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= fold: 0 training =========\n",
      "zsh:1: command not found: jupyter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d52ff86ccfe4fcd8f3f1e66ef5481e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 0:   0%|          | 0/679 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/berry/home/prakhar/signateGithub/signate_471/abc/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2184: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/mnt/berry/home/prakhar/signateGithub/signate_471/abc/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py\", line 61, in _worker\n    output = module(*input, **kwargs)\n  File \"/mnt/berry/home/prakhar/signateGithub/signate_471/abc/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/tmp/ipykernel_731279/2438982657.py\", line 10, in forward\n    output = self.model(input_ids=input_ids_titles_and_abstracts, attention_mask=attention_mask_titles_and_abstracts)\n  File \"/mnt/berry/home/prakhar/signateGithub/signate_471/abc/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/mnt/berry/home/prakhar/signateGithub/signate_471/abc/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 991, in forward\n    encoder_outputs = self.encoder(\n  File \"/mnt/berry/home/prakhar/signateGithub/signate_471/abc/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/mnt/berry/home/prakhar/signateGithub/signate_471/abc/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 582, in forward\n    layer_outputs = layer_module(\n  File \"/mnt/berry/home/prakhar/signateGithub/signate_471/abc/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/mnt/berry/home/prakhar/signateGithub/signate_471/abc/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 470, in forward\n    self_attention_outputs = self.attention(\n  File \"/mnt/berry/home/prakhar/signateGithub/signate_471/abc/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/mnt/berry/home/prakhar/signateGithub/signate_471/abc/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 401, in forward\n    self_outputs = self.self(\n  File \"/mnt/berry/home/prakhar/signateGithub/signate_471/abc/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/mnt/berry/home/prakhar/signateGithub/signate_471/abc/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 323, in forward\n    attention_scores = attention_scores / math.sqrt(self.attention_head_size)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 10.92 GiB total capacity; 3.98 GiB already allocated; 10.06 MiB free; 4.09 GiB reserved in total by PyTorch)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_731279/98506116.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_val_fbeta_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#best_model = PubMedBert()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#best_model=nn.DataParallel(best_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#best_model.to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#best_model.load_state_dict(torch.load('pubmedbert_input_best_model.pt'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_731279/2236635842.py\u001b[0m in \u001b[0;36mcross_val\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mval_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mfold_best_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold_best_val_fbeta_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVE_BEST_ONLY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_731279/3606573588.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(train_dataloader, val_dataloader, writer)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mmax_val_fbeta_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-inf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mavg_train_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mval_fbeta_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_731279/3043667488.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, val_dataloader, criterion, optimizer, scheduler, epoch)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_attention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#         print(\"logits=\",logits)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/berry/home/prakhar/signateGithub/signate_471/abc/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/berry/home/prakhar/signateGithub/signate_471/abc/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/berry/home/prakhar/signateGithub/signate_471/abc/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/berry/home/prakhar/signateGithub/signate_471/abc/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/berry/home/prakhar/signateGithub/signate_471/abc/lib/python3.8/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0;31m# have message field\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/mnt/berry/home/prakhar/signateGithub/signate_471/abc/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py\", line 61, in _worker\n    output = module(*input, **kwargs)\n  File \"/mnt/berry/home/prakhar/signateGithub/signate_471/abc/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/tmp/ipykernel_731279/2438982657.py\", line 10, in forward\n    output = self.model(input_ids=input_ids_titles_and_abstracts, attention_mask=attention_mask_titles_and_abstracts)\n  File \"/mnt/berry/home/prakhar/signateGithub/signate_471/abc/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/mnt/berry/home/prakhar/signateGithub/signate_471/abc/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 991, in forward\n    encoder_outputs = self.encoder(\n  File \"/mnt/berry/home/prakhar/signateGithub/signate_471/abc/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/mnt/berry/home/prakhar/signateGithub/signate_471/abc/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 582, in forward\n    layer_outputs = layer_module(\n  File \"/mnt/berry/home/prakhar/signateGithub/signate_471/abc/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/mnt/berry/home/prakhar/signateGithub/signate_471/abc/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 470, in forward\n    self_attention_outputs = self.attention(\n  File \"/mnt/berry/home/prakhar/signateGithub/signate_471/abc/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/mnt/berry/home/prakhar/signateGithub/signate_471/abc/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 401, in forward\n    self_outputs = self.self(\n  File \"/mnt/berry/home/prakhar/signateGithub/signate_471/abc/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/mnt/berry/home/prakhar/signateGithub/signate_471/abc/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 323, in forward\n    attention_scores = attention_scores / math.sqrt(self.attention_head_size)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 10.92 GiB total capacity; 3.98 GiB already allocated; 10.06 MiB free; 4.09 GiB reserved in total by PyTorch)\n"
     ]
    }
   ],
   "source": [
    "best_model, best_val_fbeta_score = cross_val()\n",
    "#best_model = PubMedBert()\n",
    "#best_model=nn.DataParallel(best_model)\n",
    "#best_model.to(device)\n",
    "#best_model.load_state_dict(torch.load('pubmedbert_input_best_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_val_fbeta_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = len(test_df)\n",
    "test_indices = list(range(dataset_size))\n",
    "test_data = TransformerDataset(test_df, test_indices, set_type='test')\n",
    "test_dataloader = DataLoader(test_data, batch_size=config.BATCH_SIZE)\n",
    "\n",
    "\n",
    "def predict(model):\n",
    "    val_loss = 0\n",
    "    test_pred = []\n",
    "    model.eval()\n",
    "    for step, batch in tqdm(enumerate(test_dataloader), total=len(test_dataloader)):\n",
    "#         batch = batch[0]\n",
    "        b_input_ids = batch['titles_and_abstracts']['input_ids'].to(device)\n",
    "        b_attention_mask = batch['titles_and_abstracts']['attention_mask'].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model(b_input_ids, b_attention_mask)\n",
    "            logits = logits.view(-1, 1)\n",
    "            logits = torch.sigmoid(logits)\n",
    "            logits = np.where(logits.to('cpu').detach().numpy().copy() < border, 0, 1)\n",
    "            print(logits)\n",
    "            test_pred.extend(logits)\n",
    "            \n",
    "    \n",
    "    test_pred = np.array(test_pred)\n",
    "    return test_pred\n",
    "\n",
    "test_pred = predict(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit():\n",
    "    sample_submission = pd.read_csv('data/sample_submit.csv', names=('id', 'judgement'))\n",
    "    ids = sample_submission['id'].values.reshape(-1,1)\n",
    "    \n",
    "    merged = np.concatenate((ids, test_pred), axis=1)\n",
    "    submission = pd.DataFrame(merged, columns=sample_submission.columns).astype(int)\n",
    "    return submission\n",
    "\n",
    "submission = submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('output/outputs1.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation accuracyをtensorboardで管理\n",
    "#k_foldのscoreの平均値を出す\n",
    "#f1からbetaスコアに変える"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aac5378b2f659b7e03042f36883bbb0c3f20ccc6d1897585acac59e3bb2b9166"
  },
  "kernelspec": {
   "display_name": "Signate",
   "language": "python",
   "name": "signate"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
