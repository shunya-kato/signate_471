{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264b07d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorboard\n",
    "# !pip install ipywidgets widgetsnbextension pandas-profiling\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, fbeta_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup\n",
    "import copy\n",
    "import re\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9967e691",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15b3fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b12d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8c7d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b38df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#border = len(train_df[train_df[\"judgement\"] == 1]) / len(train_df[\"judgement\"])\n",
    "border = 0.02\n",
    "print(border)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8202a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246bb09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e786e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_texts(df):\n",
    "    titles_and_abstracts = df['title_and_abstract'].values.tolist()\n",
    "    return titles_and_abstracts\n",
    "\n",
    "def get_labels(df):\n",
    "    labels = df.iloc[:, 3].values\n",
    "    return labels\n",
    "\n",
    "def clean_text(text):\n",
    "\n",
    "    if type(text) == float:\n",
    "        text = ''\n",
    "    #print(text)\n",
    "    \n",
    "    #text = text.lower()\n",
    "    \n",
    "    text = text.split()\n",
    "    text = [x.strip() for x in text]\n",
    "    text = [x.replace('\\n', ' ').replace('\\t', ' ') for x in text]\n",
    "    text = ' '.join(text)\n",
    "    text = re.sub('([.,!?()])', r' \\1 ', text)\n",
    "    #text = re.sub(r\"(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", text)\n",
    "    \n",
    "    \n",
    "    text = preprocess(text)\n",
    "    \n",
    "    #remove stopwords\n",
    "    #stop = stopwords.words('english')\n",
    "    #text = \" \".join([word for word in text.split() if word not in (stop)])\n",
    "    \n",
    "    return text\n",
    "\n",
    "def preprocess(sentence):\n",
    "    sentence = replace_double_quotation(sentence)\n",
    "    sentence = replace_garbled_text(sentence)\n",
    "    return sentence\n",
    "\n",
    "def replace_garbled_text(sentence):\n",
    "    garbled_char_table = {\n",
    "        'Â©': '©', '–': '-', '‐': '-',\n",
    "        'ﾂ｣': '£', 'ﾂｩ': '©', 'ﾂｫ': '«', 'ﾂｮ': '®', 'ﾂｰ': '°', 'ﾂｱ': '±', 'ﾂｲ': '²', 'ﾂｳ': '³', 'ﾂｴ': '´', 'ﾂｵ': 'µ', 'ﾂｷ': '·', 'ﾂｸ': '¸', 'ﾂｹ': '¹', 'ﾂｼ': '¼', 'ﾂｽ': '½', 'ﾂｾ': '¾', 'ﾂｿ': '¿', 'ﾂ': '',\n",
    "        'ﾃｷ': '÷', 'ﾃｸ': 'ø', 'ﾃ': 'a', 'ﾃ｡': 'a', 'ﾃ｢': 'a', 'ﾃ｣': 'a', 'ﾃ､': 'a', 'ﾃ･': 'a', 'ﾃｦ': 'ae', 'ﾃｧ': 'c', 'ﾃｨ': 'e', 'ﾃｩ': 'e', 'ﾃｪ': 'e', 'ﾃｫ': 'e',\n",
    "        'ﾃｬ': 'i', 'ﾃｭ': 'i', 'ﾃｮ': 'i', 'ﾃｯ': 'i', 'ﾃｱ': 'n', 'ﾃｲ': 'o', 'ﾃｳ': 'o', 'ﾃｴ': 'o', 'ﾃｵ': 'o', 'ﾃｶ': 'o', 'ﾃｹ': 'u', 'ﾃｺ': 'u', 'ﾃｻ': 'u', 'ﾃｼ': 'u', 'ﾃｽ': 'y', 'ﾃｿ': 'y', 'ﾃ': '×', \n",
    "        'ﾎｱ': 'α', 'ﾎｲ': 'β', 'ﾎｳ': 'γ', 'ﾎｴ': 'δ', 'ﾎｵ': 'ε', 'ﾎｶ': 'ζ', 'ﾎｷ': 'η', 'ﾎｸ': 'θ', 'ﾎｹ': 'ι', 'ﾎｺ': 'κ', 'ﾎｻ': 'λ', 'ﾎｼ': 'μ', 'ﾎｽ': 'ν', 'ﾎｾ': 'ξ', 'ﾎｿ': 'ο', 'ﾎ': '',\n",
    "        'ﾏ': ' ',\n",
    "        '竕､': '≤', '竕･': '≥', '竕ｦ': '≦', '竕ｧ': '≧',\n",
    "        '窶｢': '•', '窶ｦ': '…', '窶ｲ': '′', '窶ｳ': '″', '窶ｴ': '‴', '窶': ' ',\n",
    "        '竅ｰ': '⁰', '竅ｴ': '⁴', '竅ｵ': '⁵', '竅ｶ': '⁶', '竅ｷ': '⁷', '竅ｸ': '⁸', '竅ｹ': '⁹', '竅ｺ': '⁺', '竅ｻ': '⁻', '竅ｼ': '⁼', \n",
    "        '竏･': '∥', '竏ｪ': '∪', '竏ｫ': '∫', '竏ｶ': '∶', '竏ｼ': '∼', '竏': '', \n",
    "        'ﾂ\\uf8f0': ' '\n",
    "    }\n",
    "    for garbled_char, valid_char in garbled_char_table.items():\n",
    "        sentence = sentence.replace(garbled_char, valid_char)\n",
    "    sentence = re.sub('[ぁ-んァ-ンｦ-ﾟ一-龥]', '', sentence)\n",
    "    return sentence.translate(garbled_char_table)\n",
    "\n",
    "def replace_double_quotation(sentence):\n",
    "    return sentence.replace('\"', \"'\")  \n",
    "\n",
    "def clean_data(train_df):\n",
    "    train_df.loc[train_df['abstract'].isnull(), 'abstract'] = train_df['title']\n",
    "    train_df['abstract'] = train_df['abstract'].apply(clean_text)\n",
    "    train_df['title'] = train_df['title'].apply(clean_text)\n",
    "    return train_df\n",
    "\n",
    "def concat(train_df):\n",
    "    train_df['title_and_abstract'] = train_df['title'] + train_df['abstract']\n",
    "    return train_df\n",
    "\n",
    "train_df = clean_data(train_df)\n",
    "test_df= clean_data(test_df)\n",
    "train_df = concat(train_df)\n",
    "test_df = concat(test_df)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15cc20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.loc[0,'title_and_abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c230370",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.isnull().sum()\n",
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798bb290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax = sns.countplot(x='judgement', data=train_df)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be917dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = train_df['title'].tolist()\n",
    "# y = [len(t.split()) for t in title]\n",
    "# x = range(0, len(y))\n",
    "# plt.bar(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7667873",
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract = train_df['abstract'].tolist()\n",
    "# y = [len(a.split()) for a in abstract]\n",
    "# x = range(0, len(y))\n",
    "# plt.bar(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4723fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self):\n",
    "        super(Config, self).__init__()\n",
    "        \n",
    "        self.SEED = 42\n",
    "        self.MODEL_PATH = 'microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract'\n",
    "        self.NUM_LABELS = 1\n",
    "        \n",
    "        self.TOKENIZER = AutoTokenizer.from_pretrained(self.MODEL_PATH)\n",
    "        self.MAX_LENGTH = 512\n",
    "        self.BATCH_SIZE = 32\n",
    "        self.N_SPLIT = 5\n",
    "        \n",
    "        self.DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.FULL_FINETUNING = True\n",
    "        self.LR = 2e-5\n",
    "        self.OPTIMIZER = 'AdamW'\n",
    "        self.CRITERION = 'BCEWithLogitsLoss'\n",
    "        self.SAVE_BEST_ONLY = True\n",
    "        self.N_VALIDATE_DUR_TRAIN = 1\n",
    "        self.EPOCHS = 2\n",
    "        \n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec6f14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_init(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed = config.SEED\n",
    "seed_init(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb728a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDataset(Dataset):\n",
    "    def __init__(self, df, indices, set_type=None):\n",
    "        super(TransformerDataset, self).__init__()\n",
    "\n",
    "        df = df.iloc[indices]\n",
    "        self.titles_and_abstracts = get_texts(df)\n",
    "        self.set_type = set_type\n",
    "        if self.set_type != 'test':\n",
    "            self.labels = get_labels(df)\n",
    "\n",
    "        self.max_length = config.MAX_LENGTH\n",
    "        self.tokenizer = config.TOKENIZER\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.titles_and_abstracts)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        tokenized_titles_and_abstracts = self.tokenizer.encode_plus(\n",
    "            self.titles_and_abstracts[index], \n",
    "            max_length=self.max_length,\n",
    "            pad_to_max_length=True,\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_token_type_ids=False,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        input_ids_titles_and_abstracts = tokenized_titles_and_abstracts['input_ids'].squeeze()\n",
    "        attention_mask_titles_and_abstracts = tokenized_titles_and_abstracts['attention_mask'].squeeze()\n",
    "        \n",
    "\n",
    "        if self.set_type != 'test':\n",
    "            return {\n",
    "                'titles_and_abstracts': {\n",
    "                    'input_ids': input_ids_titles_and_abstracts.long(),\n",
    "                    'attention_mask': attention_mask_titles_and_abstracts.long(),\n",
    "                },\n",
    "                'labels': torch.Tensor([self.labels[index]]).float(),\n",
    "            }\n",
    "\n",
    "        return {\n",
    "            'titles_and_abstracts': {\n",
    "                'input_ids': input_ids_titles_abstracts.long(),\n",
    "                'attention_mask': attention_mask_titles_and_abstracts.long(),\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6256359f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PubMedBert(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PubMedBert, self).__init__()\n",
    "        self.model = AutoModel.from_pretrained(config.MODEL_PATH)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        self.avgpool = nn.AvgPool1d(2, 2)\n",
    "        self.linear = nn.Linear(768, config.NUM_LABELS)\n",
    "    \n",
    "    def forward(self, input_ids_titles_and_abstracts, attention_mask_titles_and_abstracts=None):\n",
    "        output = self.model(input_ids=input_ids_titles_and_abstracts, attention_mask=attention_mask_titles_and_abstracts)\n",
    "        features = output.pooler_output\n",
    "        features = features.unsqueeze(1)\n",
    "        features_pooled = self.avgpool(features)\n",
    "        features_pooled = features_pooled.squeeze(1)\n",
    "\n",
    "        x = self.dropout(features)\n",
    "        x = self.linear(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e6d7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(model, val_dataloader, criterion, epoch):\n",
    "    val_loss = 0\n",
    "    true, pred, output = [], [], []\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    for step, batch in tqdm(enumerate(val_dataloader), total=len(val_dataloader)):\n",
    "        b_input_ids = batch['titles_and_abstracts']['input_ids'].to(device)\n",
    "        b_attention_mask = batch['titles_and_abstracts']['attention_mask'].to(device)\n",
    "        b_labels = batch['labels'].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model(b_input_ids, b_attention_mask)\n",
    "            logits = logits.view(-1, 1)\n",
    "            loss = criterion(logits, b_labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            logits = torch.sigmoid(logits)\n",
    "            logits = logits.to('cpu').detach().numpy().copy()\n",
    "            output.extend(logits.tolist())\n",
    "            logits = np.where(logits < border, 0, 1)\n",
    "            labels = b_labels.to('cpu').detach().numpy().copy()\n",
    "            \n",
    "            pred.extend(logits)\n",
    "            true.extend(labels)\n",
    "            \n",
    "    output0, output1 = [], []\n",
    "    for p, o in zip(true, output):\n",
    "        if p == 0:\n",
    "            output0.append(o[0])\n",
    "        else:\n",
    "            output1.append(o[0])\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(1,2,1)\n",
    "    ax1.hist(output0, bins=100, color='red', alpha=0.5)\n",
    "    ax1.set_xlabel('output')\n",
    "    ax1.set_ylabel('sum')\n",
    "    ax1.set_title('val_0')\n",
    "    \n",
    "    ax2 = fig.add_subplot(1,2,2)\n",
    "    ax2.hist(output1, bins=100, color='blue', alpha=0.5)\n",
    "    ax2.set_xlabel('output')\n",
    "    ax2.set_ylabel('sum')\n",
    "    ax2.set_title('val_1')\n",
    "    \n",
    "    fig.savefig('graph/val'+str(epoch)+'.png')\n",
    "        \n",
    "    avg_val_loss = val_loss / len(val_dataloader)\n",
    "    print('Val loss:', avg_val_loss)\n",
    "    print('Val accuracy:', accuracy_score(true, pred))\n",
    "    \n",
    "    val_fbeta_score = fbeta_score(true, pred, beta=7.0)\n",
    "    print('Val fbeta score:', val_fbeta_score)\n",
    "    return val_fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7998f488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataloader, val_dataloader, criterion, optimizer, scheduler, epoch):\n",
    "    nv = config.N_VALIDATE_DUR_TRAIN\n",
    "    temp = len(train_dataloader) // nv\n",
    "    temp = temp - (temp%100)\n",
    "    validate_at_steps = [temp * x for x in range(1, nv+1)]\n",
    "    \n",
    "    train_loss = 0\n",
    "    true, pred, output = [], [], []\n",
    "    for step, batch in tqdm(enumerate(train_dataloader), desc='Epoch ' + str(epoch), total=len(train_dataloader)):\n",
    "        \n",
    "        model.train()\n",
    "        b_input_ids = batch['titles_and_abstracts']['input_ids'].to(device)\n",
    "        b_attention_mask = batch['titles_and_abstracts']['attention_mask'].to(device)\n",
    "        b_labels = batch['labels'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        logits = model(b_input_ids, b_attention_mask)\n",
    "        logits = logits.view(-1, 1)\n",
    "#         print(\"logits=\",logits)\n",
    "        loss = criterion(logits, b_labels)\n",
    "        train_loss += loss.item()\n",
    "#         print(train_loss)\n",
    "        \n",
    "        logits = torch.sigmoid(logits)\n",
    "        logits = logits.to('cpu').detach().numpy().copy()\n",
    "        output.extend(logits.tolist())\n",
    "        logits = np.where(logits < border, 0, 1)\n",
    "        labels = b_labels.to('cpu').detach().numpy().copy()\n",
    "            \n",
    "        pred.extend(logits)\n",
    "        true.extend(labels)\n",
    "            \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        \n",
    "        #if step in validate_at_steps:\n",
    "        #    print(f'-- Step: {step}')\n",
    "        #    _ = val(model, val_dataloader, criterion)\n",
    "        \n",
    "    output0, output1 = [], []\n",
    "    for p, o in zip(true, output):\n",
    "        if p == 0:\n",
    "            output0.append(o[0])\n",
    "        else:\n",
    "            output1.append(o[0])\n",
    "            \n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(1,2,1)\n",
    "    ax1.hist(output0, bins=100, color='red', alpha=0.5)\n",
    "    ax1.set_xlabel('output')\n",
    "    ax1.set_ylabel('sum')\n",
    "    ax1.set_title('train_0')\n",
    "\n",
    "    ax2 = fig.add_subplot(1,2,2)\n",
    "    ax2.hist(output1, bins=100, color='blue', alpha=0.5)\n",
    "    ax2.set_xlabel('output')\n",
    "    ax2.set_ylabel('sum')\n",
    "    ax2.set_title('train_1')\n",
    "    \n",
    "    fig.savefig('graph/train'+str(epoch)+'.png')\n",
    "    \n",
    "    avg_train_loss = train_loss / len(train_dataloader)\n",
    "    accuracy = accuracy_score(true, pred)\n",
    "    train_fbeta_score = fbeta_score(true, pred, beta=7.0)\n",
    "    print('Training loss:', avg_train_loss)\n",
    "    print('Training accuracy:', accuracy_score)\n",
    "    print('Train fbeta score:', train_fbeta_score)\n",
    "    return avg_train_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6866223",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(train_dataloader, val_dataloader, writer):\n",
    "    \n",
    "    !jupyter nbextension enable --py --sys-prefix widgetsnbextension\n",
    "    torch.cuda.empty_cache()\n",
    "    model = PubMedBert()\n",
    "    model=nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "    \n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    if config.FULL_FINETUNING:\n",
    "        param_optimizer = list(model.named_parameters())\n",
    "        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "        optimizer_parameters = [\n",
    "            {\n",
    "                \"params\": [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": 0.001,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": 0.0,\n",
    "            },\n",
    "        ]\n",
    "        optimizer = optim.AdamW(optimizer_parameters, lr=config.LR)\n",
    "    \n",
    "    num_training_steps = len(train_dataloader) * config.EPOCHS\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n",
    "    \n",
    "    max_val_fbeta_score = float('-inf')\n",
    "    for epoch in range(config.EPOCHS):\n",
    "        avg_train_loss, accuracy = train(model, train_dataloader, val_dataloader, criterion, optimizer, scheduler, epoch)\n",
    "        val_fbeta_score = val(model, val_dataloader, criterion, epoch)\n",
    "        \n",
    "        writer.add_scalar('train_loss', avg_train_loss, epoch+1)\n",
    "        writer.add_scalar('accuracy', accuracy, epoch+1)\n",
    "        writer.add_scalar('val_fbeta_score', val_fbeta_score, epoch+1)\n",
    "        \n",
    "        if config.SAVE_BEST_ONLY:\n",
    "            if val_fbeta_score > max_val_fbeta_score:\n",
    "                max_val_fbeta_score = val_fbeta_score\n",
    "                best_model = copy.deepcopy(model)\n",
    "                \n",
    "    return best_model, max_val_fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85d4792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val():\n",
    "    Fold = StratifiedKFold(n_splits=config.N_SPLIT, shuffle=True, random_state=seed)\n",
    "    max_val_fbeta_score = float('-inf')\n",
    "    \n",
    "    for n, (train_indices, val_indices) in enumerate(Fold.split(train_df, train_df['judgement'])):\n",
    "        print(f'========= fold: {n} training =========')\n",
    "        \n",
    "        log_dir = 'logs/fold'+str(n)\n",
    "        if not os.path.exists(log_dir):\n",
    "            os.makedirs(log_dir)\n",
    "        \n",
    "        writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "        train_data = TransformerDataset(train_df, train_indices)\n",
    "        val_data = TransformerDataset(train_df, val_indices)\n",
    "        \n",
    "        train_dataloader = DataLoader(train_data, batch_size=config.BATCH_SIZE)\n",
    "        val_dataloader = DataLoader(val_data, batch_size=config.BATCH_SIZE)\n",
    "                \n",
    "        fold_best_model, fold_best_val_fbeta_score = run(train_dataloader, val_dataloader, writer)\n",
    "        \n",
    "        if config.SAVE_BEST_ONLY:\n",
    "            if fold_best_val_fbeta_score > max_val_fbeta_score:\n",
    "                best_model = fold_best_model\n",
    "                max_val_fbeta_score = fold_best_val_fbeta_score\n",
    "                \n",
    "                model_name = 'pubmedbert_input_best_model'\n",
    "                torch.save(best_model.state_dict(), model_name+'.pt')\n",
    "        \n",
    "        writer.close()\n",
    "                \n",
    "    return best_model, max_val_fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634b88dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = config.DEVICE\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a029102b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_model, best_val_fbeta_score = cross_val()\n",
    "#best_model = PubMedBert()\n",
    "#best_model=nn.DataParallel(best_model)\n",
    "#best_model.to(device)\n",
    "#best_model.load_state_dict(torch.load('pubmedbert_input_best_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b81b8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_val_fbeta_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7373cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = len(test_df)\n",
    "test_indices = list(range(dataset_size))\n",
    "test_data = TransformerDataset(test_df, test_indices, set_type='test')\n",
    "test_dataloader = DataLoader(test_data, batch_size=config.BATCH_SIZE)\n",
    "\n",
    "\n",
    "def predict(model):\n",
    "    val_loss = 0\n",
    "    test_pred = []\n",
    "    model.eval()\n",
    "    for step, batch in tqdm(enumerate(test_dataloader), total=len(test_dataloader)):\n",
    "#         batch = batch[0]\n",
    "        b_input_ids = batch['titles_and_abstracts']['input_ids'].to(device)\n",
    "        b_attention_mask = batch['titles_and_abstracts']['attention_mask'].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model(b_input_ids, b_attention_mask)\n",
    "            logits = logits.view(-1, 1)\n",
    "            logits = torch.sigmoid(logits)\n",
    "            logits = np.where(logits.to('cpu').detach().numpy().copy() < border, 0, 1)\n",
    "            test_pred.extend(logits)\n",
    "    \n",
    "    test_pred = np.array(test_pred)\n",
    "    return test_pred\n",
    "\n",
    "test_pred = predict(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4386b792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit():\n",
    "    sample_submission = pd.read_csv('data/sample_submit.csv', names=('id', 'judgement'))\n",
    "    ids = sample_submission['id'].values.reshape(-1,1)\n",
    "    \n",
    "    merged = np.concatenate((ids, test_pred), axis=1)\n",
    "    submission = pd.DataFrame(merged, columns=sample_submission.columns).astype(int)\n",
    "    return submission\n",
    "\n",
    "submission = submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da27dc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('output/outputs.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8101f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation accuracyをtensorboardで管理\n",
    "#k_foldのscoreの平均値を出す\n",
    "#f1からbetaスコアに変える"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aac5378b2f659b7e03042f36883bbb0c3f20ccc6d1897585acac59e3bb2b9166"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
