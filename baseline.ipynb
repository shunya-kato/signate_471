{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e33a257",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-31 00:11:21.460592: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64:/usr/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/local/cuda/lib64:/usr/lib64:/usr/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/local/cuda/lib64:\n",
      "2021-08-31 00:11:21.460663: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import texthero as hero\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45be5841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Aug 31 00:13:48 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 108...  On   | 00000000:04:00.0 Off |                  N/A |\n",
      "| 23%   30C    P8     8W / 250W |     12MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce GTX 108...  On   | 00000000:06:00.0 Off |                  N/A |\n",
      "| 23%   32C    P8     9W / 250W |      1MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce GTX 108...  On   | 00000000:07:00.0 Off |                  N/A |\n",
      "| 23%   27C    P8     7W / 250W |      1MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce GTX 1080    On   | 00000000:08:00.0 Off |                  N/A |\n",
      "| 28%   31C    P8     6W / 180W |      1MiB /  8119MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  GeForce GTX 1080    On   | 00000000:0C:00.0 Off |                  N/A |\n",
      "| 27%   31C    P8     6W / 180W |      1MiB /  8119MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  GeForce GTX 108...  On   | 00000000:0D:00.0 Off |                  N/A |\n",
      "|  0%   28C    P8     8W / 250W |      1MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  GeForce GTX 108...  On   | 00000000:0E:00.0 Off |                  N/A |\n",
      "|  0%   32C    P8     8W / 250W |      1MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  GeForce GTX 108...  On   | 00000000:0F:00.0 Off |                  N/A |\n",
      "|  0%   25C    P8     8W / 250W |      1MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0558c4bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d1ef755",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4692c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>judgement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>One-year age changes in MRI brain volumes in o...</td>\n",
       "      <td>Longitudinal studies indicate that declines in...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Supportive CSF biomarker evidence to enhance t...</td>\n",
       "      <td>The present study was undertaken to validate t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Occurrence of basal ganglia germ cell tumors w...</td>\n",
       "      <td>Objective: To report a case series in which ba...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>New developments in diagnosis and therapy of C...</td>\n",
       "      <td>The etiology and pathogenesis of idiopathic ch...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Prolonged shedding of SARS-CoV-2 in an elderly...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title  \\\n",
       "0   0  One-year age changes in MRI brain volumes in o...   \n",
       "1   1  Supportive CSF biomarker evidence to enhance t...   \n",
       "2   2  Occurrence of basal ganglia germ cell tumors w...   \n",
       "3   3  New developments in diagnosis and therapy of C...   \n",
       "4   4  Prolonged shedding of SARS-CoV-2 in an elderly...   \n",
       "\n",
       "                                            abstract  judgement  \n",
       "0  Longitudinal studies indicate that declines in...          0  \n",
       "1  The present study was undertaken to validate t...          0  \n",
       "2  Objective: To report a case series in which ba...          0  \n",
       "3  The etiology and pathogenesis of idiopathic ch...          0  \n",
       "4                                                NaN          0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2939bdf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.023282372444280715\n"
     ]
    }
   ],
   "source": [
    "border = len(train_df[train_df[\"judgement\"] == 1]) / len(train_df[\"judgement\"])\n",
    "print(border)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d636beb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27145"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f36cbdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              0\n",
       "title           0\n",
       "abstract     4390\n",
       "judgement       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9da0217f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>judgement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>One-year age changes in MRI brain volumes in o...</td>\n",
       "      <td>Longitudinal studies indicate that declines in...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Supportive CSF biomarker evidence to enhance t...</td>\n",
       "      <td>The present study was undertaken to validate t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Occurrence of basal ganglia germ cell tumors w...</td>\n",
       "      <td>Objective: To report a case series in which ba...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>New developments in diagnosis and therapy of C...</td>\n",
       "      <td>The etiology and pathogenesis of idiopathic ch...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Prolonged shedding of SARS-CoV-2 in an elderly...</td>\n",
       "      <td>Prolonged shedding of SARS-CoV-2 in an elderly...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title  \\\n",
       "0   0  One-year age changes in MRI brain volumes in o...   \n",
       "1   1  Supportive CSF biomarker evidence to enhance t...   \n",
       "2   2  Occurrence of basal ganglia germ cell tumors w...   \n",
       "3   3  New developments in diagnosis and therapy of C...   \n",
       "4   4  Prolonged shedding of SARS-CoV-2 in an elderly...   \n",
       "\n",
       "                                            abstract  judgement  \n",
       "0  Longitudinal studies indicate that declines in...          0  \n",
       "1  The present study was undertaken to validate t...          0  \n",
       "2  Objective: To report a case series in which ba...          0  \n",
       "3  The etiology and pathogenesis of idiopathic ch...          0  \n",
       "4  Prolonged shedding of SARS-CoV-2 in an elderly...          0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_data(train_df):\n",
    "    train_df.loc[train_df['abstract'].isnull(), 'abstract'] = train_df['title']\n",
    "    return train_df\n",
    "\n",
    "def get_texts(df):\n",
    "    titles = df['title'].values.tolist()\n",
    "    abstracts = df['abstract'].values.tolist()\n",
    "    return titles, abstracts\n",
    "\n",
    "def get_labels(df):\n",
    "    labels = df.iloc[:, 3].values\n",
    "    return labels\n",
    "    \n",
    "train_df = clean_data(train_df)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41a045fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           0\n",
       "title        0\n",
       "abstract     0\n",
       "judgement    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66e8bb59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.countplot(x='judgement', data=train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7f581c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 27145 artists>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "title = train_df['title'].tolist()\n",
    "y = [len(t.split()) for t in title]\n",
    "x = range(0, len(y))\n",
    "plt.bar(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a4add6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 27145 artists>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "abstract = train_df['abstract'].tolist()\n",
    "y = [len(a.split()) for a in abstract]\n",
    "x = range(0, len(y))\n",
    "plt.bar(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aff13c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self):\n",
    "        super(Config, self).__init__()\n",
    "        \n",
    "        self.SEED = 42\n",
    "        self.MODEL_PATH = 'allenai/scibert_scivocab_uncased'\n",
    "        self.NUM_LABELS = 1\n",
    "        \n",
    "        self.TOKENIZER = AutoTokenizer.from_pretrained(self.MODEL_PATH)\n",
    "        self.MAX_LENGTH1 = 24\n",
    "        self.MAX_LENGTH2 = 512\n",
    "        self.BATCH_SIZE = 4\n",
    "        self.VALIDATION_SPLIT = 0.2\n",
    "        \n",
    "        self.DEVICE = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "        self.FULL_FINETUNING = True\n",
    "        self.LR = 1e-5\n",
    "        self.OPTIMIZER = 'AdamW'\n",
    "        self.CRITERION = 'BCEWithLogitsLoss'\n",
    "        self.SAVE_BEST_ONLY = True\n",
    "        self.N_VALIDATE_DUR_TRAIN = 1\n",
    "        self.EPOCHS = 5\n",
    "        \n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c6e8981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_init(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed = config.SEED\n",
    "seed_init(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13d44a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDataset(Dataset):\n",
    "    def __init__(self, df, indices, set_type=None):\n",
    "        super(TransformerDataset, self).__init__()\n",
    "\n",
    "        df = df.iloc[indices]\n",
    "        self.titles, self.abstracts = get_texts(df)\n",
    "        self.set_type = set_type\n",
    "        if self.set_type != 'test':\n",
    "            self.labels = get_labels(df)\n",
    "\n",
    "        self.max_length1 = config.MAX_LENGTH1\n",
    "        self.max_length2 = config.MAX_LENGTH2\n",
    "        self.tokenizer = config.TOKENIZER\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.titles)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        tokenized_titles = self.tokenizer.encode_plus(\n",
    "            self.titles[index], \n",
    "            max_length=self.max_length1,\n",
    "            pad_to_max_length=True,\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_token_type_ids=False,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        input_ids_titles = tokenized_titles['input_ids'].squeeze()\n",
    "        attention_mask_titles = tokenized_titles['attention_mask'].squeeze()\n",
    "        \n",
    "        tokenized_abstracts = self.tokenizer.encode_plus(\n",
    "            self.abstracts[index], \n",
    "            max_length=self.max_length2,\n",
    "            pad_to_max_length=True,\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_token_type_ids=False,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        input_ids_abstracts = tokenized_abstracts['input_ids'].squeeze()\n",
    "        attention_mask_abstracts = tokenized_abstracts['attention_mask'].squeeze()\n",
    "\n",
    "        if self.set_type != 'test':\n",
    "            return {\n",
    "                'titles': {\n",
    "                    'input_ids': input_ids_titles.long(),\n",
    "                    'attention_mask': attention_mask_titles.long(),\n",
    "                },\n",
    "                'abstracts': {\n",
    "                    'input_ids': input_ids_abstracts.long(),\n",
    "                    'attention_mask': attention_mask_abstracts.long(),\n",
    "                },\n",
    "                'labels': torch.Tensor([self.labels[index]]).float(),\n",
    "            }\n",
    "\n",
    "        return {\n",
    "            'titles': {\n",
    "                'input_ids': input_ids_titles.long(),\n",
    "                'attention_mask': attention_mask_titles.long(),\n",
    "            },\n",
    "            'abstracts': {\n",
    "                'input_ids': input_ids_abstracts.long(),\n",
    "                'attention_mask': attention_mask_abstracts.long(),\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "708f6462",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualSciBert(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DualSciBert, self).__init__()\n",
    "        self.titles_model = AutoModel.from_pretrained(config.MODEL_PATH)\n",
    "        self.abstracts_model = AutoModel.from_pretrained(config.MODEL_PATH)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        self.avgpool = nn.AvgPool1d(2, 2)\n",
    "        self.output = nn.Linear(768, config.NUM_LABELS)\n",
    "    \n",
    "    def forward(self, input_ids_titles, attention_mask_titles=None, input_ids_abstracts=None, attention_mask_abstracts=None):\n",
    "        output = self.titles_model(input_ids=input_ids_titles, attention_mask=attention_mask_titles)\n",
    "        titles_features = output.pooler_output\n",
    "        titles_features = titles_features.unsqueeze(1)\n",
    "        titles_features_pooled = self.avgpool(titles_features)\n",
    "        titles_features_pooled = titles_features_pooled.squeeze(1)\n",
    "        \n",
    "        output = self.abstracts_model(input_ids=input_ids_abstracts, attention_mask=attention_mask_abstracts)\n",
    "        abstracts_features = output.pooler_output\n",
    "        abstracts_features = abstracts_features.unsqueeze(1)\n",
    "        abstracts_features_pooled = self.avgpool(abstracts_features)\n",
    "        abstracts_features_pooled = abstracts_features_pooled.squeeze(1)\n",
    "        \n",
    "        combined_features = torch.cat((titles_features_pooled, abstracts_features_pooled), dim=1)\n",
    "        x = self.dropout(combined_features)\n",
    "        x = self.output(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "312924e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(model, val_dataloader, criterion):\n",
    "    val_loss = 0\n",
    "    true, pred = [], []\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    for step, batch in tqdm(enumerate(val_dataloader), total=len(val_dataloader)):\n",
    "        b_input_ids_titles = batch['titles']['input_ids'].to(device)\n",
    "        b_attention_mask_titles = batch['titles']['attention_mask'].to(device)\n",
    "        b_input_ids_abstracts = batch['abstracts']['input_ids'].to(device)\n",
    "        b_attention_mask_abstracts = batch['abstracts']['attention_mask'].to(device)\n",
    "        b_labels = batch['labels'].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model(b_input_ids_titles, b_attention_mask_titles, b_input_ids_abstracts, b_attention_mask_abstracts)\n",
    "            loss = criterion(logits, b_labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            logits = torch.sigmoid(logits)\n",
    "            logits = np.where(logits.to('cpu').detach().numpy().copy() < border, 0, 1)\n",
    "            labels = b_labels.to('cpu').detach().numpy().copy()\n",
    "            \n",
    "            pred.extend(logits)\n",
    "            true.extend(labels)\n",
    "        \n",
    "    avg_val_loss = val_loss / len(val_dataloader)\n",
    "    print('Val loss:', avg_val_loss)\n",
    "    print('Val accuracy:', accuracy_score(true, pred))\n",
    "    \n",
    "    val_micro_f1_score = f1_score(true, pred, average='micro')\n",
    "    print('Val micro f1 score:', val_micro_f1_score)\n",
    "    return val_micro_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79a12cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataloader, val_dataloader, criterion, optimizer, scheduler, epoch):\n",
    "    nv = config.N_VALIDATE_DUR_TRAIN\n",
    "    temp = len(train_dataloader) // nv\n",
    "    temp = temp - (temp%100)\n",
    "    validate_at_steps = [temp * x for x in range(1, nv+1)]\n",
    "    \n",
    "    train_loss = 0\n",
    "    true, pred = [], []\n",
    "    for step, batch in tqdm(enumerate(train_dataloader), desc='Epoch ' + str(epoch), total=len(train_dataloader)):\n",
    "        \n",
    "        model.train()\n",
    "        b_input_ids_titles = batch['titles']['input_ids'].to(device)\n",
    "        b_attention_mask_titles = batch['titles']['attention_mask'].to(device)\n",
    "        b_input_ids_abstracts = batch['abstracts']['input_ids'].to(device)\n",
    "        b_attention_mask_abstracts = batch['abstracts']['attention_mask'].to(device)\n",
    "        b_labels = batch['labels'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        logits = model(b_input_ids_titles, b_attention_mask_titles, b_input_ids_abstracts, b_attention_mask_abstracts)\n",
    "        \n",
    "        loss = criterion(logits, b_labels)\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        logits = torch.sigmoid(logits)\n",
    "        logits = np.where(logits.to('cpu').detach().numpy().copy() < border, 0, 1)\n",
    "        labels = b_labels.to('cpu').detach().numpy().copy()\n",
    "            \n",
    "        pred.extend(logits)\n",
    "        true.extend(labels)\n",
    "            \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        if step in validate_at_steps:\n",
    "            print(f'-- Step: {step}')\n",
    "            _ = val(model, val_dataloader, criterion)\n",
    "            \n",
    "    avg_train_loss = train_loss / len(train_dataloader)\n",
    "    accuracy = accuracy_score(true, pred)\n",
    "    print('Training loss:', avg_train_loss)\n",
    "    print('Training accuracy:', accuracy_score)\n",
    "    return avg_train_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84b54ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(train_dataloader, val_dataloader, writer):\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    if config.FULL_FINETUNING:\n",
    "        param_optimizer = list(model.named_parameters())\n",
    "        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "        optimizer_parameters = [\n",
    "            {\n",
    "                \"params\": [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": 0.001,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": 0.0,\n",
    "            },\n",
    "        ]\n",
    "        optimizer = optim.AdamW(optimizer_parameters, lr=config.LR)\n",
    "    \n",
    "    num_training_steps = len(train_dataloader) * config.EPOCHS\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n",
    "    \n",
    "    max_val_micro_f1_score = float('-inf')\n",
    "    for epoch in range(config.EPOCHS):\n",
    "        avg_train_loss, accuracy = train(model, train_dataloader, val_dataloader, criterion, optimizer, scheduler, epoch)\n",
    "        val_micro_f1_score = val(model, val_dataloader, criterion)\n",
    "        \n",
    "        writer.add_scalar('train_loss', avg_train_loss, epoch+1)\n",
    "        writer.add_scalar('accuracy', accuracy)\n",
    "        \n",
    "        if config.SAVE_BEST_ONLY:\n",
    "            if val_micro_f1_score > max_val_micro_f1_score:\n",
    "                best_model = copy.deepcopy(model)\n",
    "                best_val_micro_f1_score = val_micro_f1_score\n",
    "                \n",
    "    return best_model, best_val_micro_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "619cad89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val():\n",
    "    Fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    max_val_micro_f1_score = float('-inf')\n",
    "    \n",
    "    for n, (train_indices, val_indices) in enumerate(Fold.split(train_df, train_df['judgement'])):\n",
    "        print(f'========= fold: {n} training =========')\n",
    "        \n",
    "        log_dir = 'logs/fold'+str(n)\n",
    "        if not os.path.exists(log_dir):\n",
    "            os.makedirs(log_dir)\n",
    "        \n",
    "        writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "        train_data = TransformerDataset(train_df, train_indices)\n",
    "        val_data = TransformerDataset(train_df, val_indices)\n",
    "        \n",
    "        train_dataloader = DataLoader(train_data, batch_size=config.BATCH_SIZE)\n",
    "        val_dataloader = DataLoader(val_data, batch_size=config.BATCH_SIZE)\n",
    "                \n",
    "        fold_best_model, fold_best_val_micro_f1_score = run(train_dataloader, val_dataloader, writer)\n",
    "        \n",
    "        if config.SAVE_BEST_ONLY:\n",
    "            if fold_val_micro_f1_score > max_val_micro_f1_score:\n",
    "                best_model = fold_best_model\n",
    "                best_val_micro_f1_score = fold_val_micro_f1_score\n",
    "                \n",
    "                model_name = 'scibert_dualinput_best_model'\n",
    "                torch.save(best_model.state_dict(), model_name+'.pt')\n",
    "        \n",
    "        writer.close()\n",
    "                \n",
    "    return best_model, best_val_micro_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "772f761b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = config.DEVICE\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "213f364c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= fold: 0 training =========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e47b655fcdbc4954a50ee8994d847b44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 0:   0%|          | 0/5429 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/berry/home/s-kato/.venv/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2184: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Step: 5400\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ad92f5b3fac4e4092e6cafcaf260663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1358 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'logitsto' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3980388/1243818814.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDualSciBert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbest_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_val_micro_f1_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_3980388/523324856.py\u001b[0m in \u001b[0;36mcross_val\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mval_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mfold_best_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold_best_val_micro_f1_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVE_BEST_ONLY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3980388/2051548988.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(train_dataloader, val_dataloader, writer)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mmax_val_micro_f1_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-inf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mavg_train_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mval_micro_f1_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3980388/1533781621.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, val_dataloader, criterion, optimizer, scheduler, epoch)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalidate_at_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'-- Step: {step}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mavg_train_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3980388/4078568806.py\u001b[0m in \u001b[0;36mval\u001b[0;34m(model, val_dataloader, criterion)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogitsto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mborder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb_labelsto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'logitsto' is not defined"
     ]
    }
   ],
   "source": [
    "model = DualSciBert()\n",
    "model.to(device)\n",
    "best_model, best_val_micro_f1_score = cross_val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba860f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = len(test_df)\n",
    "test_indices = list(range(dataset_size))\n",
    "test_data = TransformerDataset(test_df, test_indices, set_type='test')\n",
    "test_dataloader = DataLoader(test_data, batch_size=config.BATCH_SIZE)\n",
    "\n",
    "def predict(model):\n",
    "    val_loss = 0\n",
    "    test_pred = []\n",
    "    model.eval()\n",
    "    for step, batch in tqdm(enumerate(test_dataloader), total=len(test_dataloader)):\n",
    "        batch = batch[0]\n",
    "        b_input_ids_titles = batch['titles']['input_ids'].to(device)\n",
    "        b_attention_mask_titles = batch['titles']['attention_mask'].to(device)\n",
    "        b_input_ids_abstracts = batch['abstracts']['input_ids'].to(device)\n",
    "        b_attention_mask_abstracts = batch['abstracts']['attention_mask'].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model(b_input_ids_titles, b_attention_mask_titles, b_input_ids_abstracts, b_attention_mask_abstracts)\n",
    "            logits = torch.sigmoid(logits)\n",
    "            logits = np.where(logits.to('cpu').detach().numpy().copy() < border, 0, 1)\n",
    "            test_pred.extend(logits)\n",
    "    \n",
    "    test_pred = np.array(test_pred)\n",
    "    return test_pred\n",
    "\n",
    "test_pred = predict(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d2d7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit():\n",
    "    sample_submission = pd.read_csv('data/sample_submit.csv', names=('id', 'judgement'))\n",
    "    ids = sample_submission['id'].values.reshape(-1,1)\n",
    "    \n",
    "    merged = np.concatenate((ids, test_pred), axis=1)\n",
    "    submission = pd.DataFrame(merged, columns=sample_submission.columns).astype(int)\n",
    "    return submission\n",
    "\n",
    "submission = submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa225bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('output/baseline.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b4422d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation accuracytensorboard\n",
    "#k_foldscore\n",
    "#f1beta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
